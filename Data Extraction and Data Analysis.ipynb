{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1bc1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cbd953",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_excel(\"Input.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d8a21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.iloc[0:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5675f47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4b89ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.drop('URL_ID',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81727202",
   "metadata": {},
   "source": [
    "# Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6518320",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting text from all the url\n",
    "url_id=37\n",
    "for i in range(0,len(df)):\n",
    "    \n",
    " \n",
    "    link=df.iloc[i].values\n",
    "   \n",
    "    headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/106.0.0.0 Safari/537.36'\n",
    "    } #giving user access\n",
    "    req=requests.get(link[0],headers=headers)\n",
    "    soup=BeautifulSoup(req.content,'html.parser')\n",
    "    content=soup.find_all(attrs={'class':'td-post-content'}) or soup.find_all(attrs={'class':\"td-404-sub-title\"})\n",
    "    content=content[0].text.replace('\\xa0',\"  \").replace('\\n',\" \")\n",
    "    title=soup.find_all(attrs={'class':'entry-title'}) \n",
    "    title=title[16].text.replace('\\n',\"  \").replace('/',\"\")\n",
    "    text=title+ '.'+content\n",
    "    text=np.array(text)\n",
    "    text.reshape(1,-1)\n",
    "    df1=pd.Series(text)\n",
    "    filename=str(url_id)+'.'+'txt'\n",
    "    with open(filename,'a',encoding='utf-8') as f:\n",
    "        df1.to_csv(f,line_terminator=',',index=False,header=False)\n",
    "        #files.download(filename)\n",
    "    url_id+=1    \n",
    " \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fd2fd5",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac9ca6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=pd.read_csv('150.txt',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b8f140",
   "metadata": {},
   "outputs": [],
   "source": [
    "text.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a6dba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd233f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text.drop(1,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e9eb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=text.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c866ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "a=text[0].str.split('([\\.]\\s)',expand=False).explode()\n",
    "b=pd.DataFrame(a)\n",
    "b.columns=['abc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24ded7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_remove(x):\n",
    "    nopunc=[char for char in x if char!='.']\n",
    "    return''.join(nopunc)\n",
    "b['abc']=b['abc'].apply(char_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d971c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "null=b.replace('',np.nan,regex=True)\n",
    "null=null.mask(null==\" \")\n",
    "null=null.dropna()\n",
    "null.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf728a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42d4dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1adf9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "punc=[punc for punc in string.punctuation]\n",
    "punc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630d903d",
   "metadata": {},
   "outputs": [],
   "source": [
    "StopWords_Auditor=pd.read_csv('C:/Users/abc/Project/StopWords/StopWords_Auditor.txt',header=None)\n",
    "StopWords_Currencies=pd.read_csv('C:/Users/abc/Project/StopWords/StopWords_Currencies.txt',header=None,sep='|',encoding='latin-1')\n",
    "StopWords_DatesandNumbers=pd.read_csv('C:/Users/abc/Project/StopWords/StopWords_DatesandNumbers.txt',header=None)\n",
    "StopWords_Generic=pd.read_csv('C:/Users/abc/Project/StopWords/StopWords_Generic.txt',header=None)\n",
    "StopWords_GenericLong=pd.read_csv('C:/Users/abc/Project/StopWords/StopWords_GenericLong.txt',header=None)\n",
    "StopWords_Geographic=pd.read_csv('C:/Users/abc/Project/StopWords/StopWords_Geographic.txt',header=None)\n",
    "StopWords_Names=pd.read_csv('C:/Users/abc/Project/StopWords/StopWords_Names.txt',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77fd15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_process(text):\n",
    "    nopunc =[char for char in text if char not in punc or char not in [':',',','(',')','â€™','?']]\n",
    "    nopunc=''.join(nopunc)\n",
    "    txt=' '.join([word for word in nopunc.split() if word.lower() not in StopWords_Auditor])\n",
    "    txt1=' '.join([word for word in txt.split() if word.lower() not in StopWords_Currencies])\n",
    "    txt2=' '.join([word for word in txt1.split() if word.lower() not in StopWords_DatesandNumbers])\n",
    "    txt3=' '.join([word for word in txt2.split() if word.lower() not in StopWords_Generic])\n",
    "    txt4=' '.join([word for word in txt3.split() if word.lower() not in StopWords_GenericLong])\n",
    "    txt5=' '.join([word for word in txt4.split() if word.lower() not in StopWords_Geographic])\n",
    "    return ' '.join([word for word in txt5.split() if word.lower() not in StopWords_Names])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762de406",
   "metadata": {},
   "outputs": [],
   "source": [
    "null['abc']=null['abc'].apply(text_process)\n",
    "null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f14d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive=pd.read_csv('C:/Users/abc/Project/MasterDictionary/negative-words.txt',header=None,encoding='latin-1')\n",
    "negative=pd.read_csv('C:/Users/abc/Project/MasterDictionary/positive-words.txt',header=None,encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63657758",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive.columns=['abc']\n",
    "negative.columns=['abc']\n",
    "positive['abc']=positive['abc'].astype(str)\n",
    "negative['abc']=negative['abc'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5a1a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive['abc']=positive['abc'].apply(text_process)\n",
    "negative['abc']=negative['abc'].apply(text_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856d0987",
   "metadata": {},
   "outputs": [],
   "source": [
    "#positive list\n",
    "length=positive.shape[0]\n",
    "post=[]\n",
    "for i in range(0,length):\n",
    "    nopunc =[char for char in positive.iloc[i] if char not in string.punctuation or char != '+']\n",
    "    nopunc=''.join(nopunc)\n",
    "\n",
    "    post.append(nopunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0027e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#negative list\n",
    "length=negative.shape[0]\n",
    "neg=[]\n",
    "for i in range(0,length):\n",
    "    nopunc =[char for char in negative.iloc[i] if char not in string.punctuation or char != '+']\n",
    "    nopunc=''.join(nopunc)\n",
    "    neg.append(nopunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf11b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing tokenize library\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220fc1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_list=[]\n",
    "length=null.shape[0]\n",
    "for i in range(0,length):\n",
    "    txt=' '.join([word for word in null.iloc[i]])\n",
    "    txt_list.append(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f940a21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e83724d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenization of text\n",
    "tokenize_text=[]\n",
    "for i in txt_list:\n",
    "    tokenize_text+=(word_tokenize(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ad8730",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcb1501",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tokenize_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab67f81",
   "metadata": {},
   "source": [
    "# POSITIVE SCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c254a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_score=0\n",
    "for i in tokenize_text:\n",
    "    if(i.lower() in post):\n",
    "        positive_score+=1\n",
    "print('postive score=', positive_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e85cbc",
   "metadata": {},
   "source": [
    "# NEGATIVE SCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e4ecda",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_score=0\n",
    "for i in tokenize_text:\n",
    "    if(i.lower() in neg):\n",
    "        negative_score+=1\n",
    "print('negative score=', negative_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c484dcf",
   "metadata": {},
   "source": [
    "# POLARITY SCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc40ba7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Polarity Score = (Positive Score â€“ Negative Score)/ ((Positive Score + Negative Score) + 0.000001)\n",
    "Polarity_Score=(positive_score-negative_score)/((positive_score+negative_score)+0.000001)\n",
    "print('polarity_score=', Polarity_Score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d6cef4",
   "metadata": {},
   "source": [
    "# SUBJECTIVITY SCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8c5ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subjectivity Score = (Positive Score + Negative Score)/ ((Total Words after cleaning) + 0.000001)\n",
    "subjectiivity_score=(positive_score-negative_score)/((len(tokenize_text))+ 0.000001)\n",
    "print('subjectivity_score',subjectiivity_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a620950",
   "metadata": {},
   "source": [
    "# AVG. SENTENCE LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f23cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "length=null.shape[0]\n",
    "avg_length=[]\n",
    "for i in range(0,length):\n",
    "    avg_length.append(len(null['abc'].iloc[i]))\n",
    "avg_senetence_length=sum(avg_length)/len(avg_length)\n",
    "print('avg sentence length=', avg_senetence_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abfb598",
   "metadata": {},
   "source": [
    "# PERCENTAGE OF COMPLEX WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399d9fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vowels=['a','e','i','o','u']\n",
    "import re\n",
    "count=0\n",
    "complex_Word_Count=0\n",
    "for i in tokenize_text:\n",
    "    x=re.compile('[es|ed]$')\n",
    "    if x.match(i.lower()):\n",
    "        count+=0\n",
    "    else:\n",
    "        for j in i:\n",
    "            if(j.lower() in vowels ):\n",
    "                count+=1\n",
    "    if(count>2):\n",
    "        complex_Word_Count+=1\n",
    "    count=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4c4a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Percentage_of_Complex_words=complex_Word_Count/len(tokenize_text)\n",
    "print('percentag of complex words= ',Percentage_of_Complex_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db29a2e8",
   "metadata": {},
   "source": [
    "# FOG INDEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45afb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fog Index = 0.4 * (Average Sentence Length + Percentage of Complex words)\n",
    "Fog_Index = 0.4 * (avg_senetence_length + Percentage_of_Complex_words)\n",
    "print('fog index= ',Fog_Index )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b20ff02",
   "metadata": {},
   "source": [
    "# AVG. NUMBER OF EORDS PER SENTENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23605e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "length=null.shape[0]\n",
    "avg_length=[]\n",
    "for i in range(0,length):\n",
    "    a=[word.split( ) for word in null.iloc[i]]\n",
    "    avg_length.append(len(a[0]))\n",
    "    a=0\n",
    "#avg\n",
    "avg_no_of_words_per_sentence=sum(avg_length)/length\n",
    "print(\"avg no of words per sentence= \",avg_no_of_words_per_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282839fb",
   "metadata": {},
   "source": [
    "# COMPLEX WORD COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4d5dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vowels=['a','e','i','o','u']\n",
    "import re\n",
    "count=0\n",
    "complex_Word_Count=0\n",
    "for i in tokenize_text:\n",
    "    x=re.compile('[es|ed]$')\n",
    "    if x.match(i.lower()):\n",
    "        count+=0\n",
    "    else:\n",
    "        for j in i:\n",
    "            if(j.lower() in vowels ):\n",
    "                count+=1\n",
    "    if(count>2):\n",
    "        complex_Word_Count+=1\n",
    "    count=0\n",
    "print('complex words count=',  complex_Word_Count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed66681a",
   "metadata": {},
   "source": [
    "# WORD COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c49df7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count=len(tokenize_text)\n",
    "print('word count= ', word_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbf2ca5",
   "metadata": {},
   "source": [
    "# SYLLABLE PER WORD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbff53cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "vowels=['a','e','i','o','u']\n",
    "import re\n",
    "count=0\n",
    "for i in tokenize_text:\n",
    "    x=re.compile('[es|ed]$')\n",
    "    if x.match(i.lower()):\n",
    "        count+=0\n",
    "    else:\n",
    "        for j in i:\n",
    "            if(j.lower() in vowels ):\n",
    "                count+=1\n",
    "syllable_count=count\n",
    "print('syllable_per_word= ',syllable_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483ac082",
   "metadata": {},
   "source": [
    "# PERSONAL PRONOUNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2850f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pronouns=['i','we','my','ours','us' ]\n",
    "import re\n",
    "count=0\n",
    "for i in tokenize_text:\n",
    "    if i.lower() in pronouns:\n",
    "        count+=1\n",
    "personal_pronouns=count\n",
    "print('personal pronouns= ',personal_pronouns )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41dc2f0",
   "metadata": {},
   "source": [
    "# AVG WORD LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e75816",
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "for i in tokenize_text:\n",
    "    for j in i:\n",
    "        count+=1\n",
    "avg_word_length=count/len(tokenize_text)\n",
    "print('avg word= ', avg_word_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160abb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "data={'positive_score':positive_score,'negative_score':negative_score,'Polarity_Score':Polarity_Score,'subjectiivity_score':subjectiivity_score,'avg_senetence_length':avg_senetence_length,'Percentage_of_Complex_words':Percentage_of_Complex_words,'Fog_Index':Fog_Index,'avg_no_of_words_per_sentence':avg_no_of_words_per_sentence,'complex_Word_Count':complex_Word_Count,'word_count':word_count,'syllable_count':syllable_count,'personal_pronouns':personal_pronouns,'avg_word_length':avg_word_length}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6779656a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#output=pd.DataFrame()\n",
    "output=output.append(data,ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64123a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.columns=['positive_score','negative_score','Polarity_Score','subjectiivity_score','avg_senetence_length','Percentage_of_Complex_words','Fog_Index','avg_no_of_words_per_sentence','complex_Word_Count','word_count','syllable_count','personal_pronouns','avg_word_length']\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c8f85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output.excel', 'a') as f:#creating text file \n",
    "    output.to_excel(f, index=False, header=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7abe00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69826a34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81955cfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10da4787",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cbeb3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b9ed8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a878dfa9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
